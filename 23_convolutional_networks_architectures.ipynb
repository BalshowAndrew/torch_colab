{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e181825e",
   "metadata": {},
   "source": [
    "# Convolutional Networks Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422c7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision as tv\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bf257e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b9a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device):\n",
    "    acc_sum, n = 0, 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        acc_sum +=(net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e7e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, optimizer, num_epochs, device):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Step {i}, time since epoch: {time.time() - start:.3f}. \"\n",
    "                      f\"Train acc: {train_acc_sum / n:.3f}. Train Loss: {train_l_sum / n:.3f}\")\n",
    "        test_acc = evaluate_accuracy(test_iter, net.to(device), device)\n",
    "        print(f\"epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}\" \\\n",
    "              f\", test acc {test_acc:.3f}, time {time.time() - start:.1f} sec\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1268d13",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f70cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 39.4MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.13MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.1MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.71MB/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "transforms = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((224, 224)),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "train_dataset = tv.datasets.MNIST('./datas', train=True, transform=transforms, download=True)\n",
    "test_dataset = tv.datasets.MNIST('./datas', train=False, transform=transforms, download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a842a8",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87df0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(6400, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8081855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 54, 54]          11,712\n",
      "              ReLU-2           [-1, 96, 54, 54]               0\n",
      "         MaxPool2d-3           [-1, 96, 26, 26]               0\n",
      "            Conv2d-4          [-1, 256, 26, 26]         614,656\n",
      "              ReLU-5          [-1, 256, 26, 26]               0\n",
      "         MaxPool2d-6          [-1, 256, 12, 12]               0\n",
      "            Conv2d-7          [-1, 384, 12, 12]         885,120\n",
      "              ReLU-8          [-1, 384, 12, 12]               0\n",
      "            Conv2d-9          [-1, 384, 12, 12]       1,327,488\n",
      "             ReLU-10          [-1, 384, 12, 12]               0\n",
      "           Conv2d-11          [-1, 256, 12, 12]         884,992\n",
      "             ReLU-12          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-13            [-1, 256, 5, 5]               0\n",
      "          Flatten-14                 [-1, 6400]               0\n",
      "           Linear-15                 [-1, 4096]      26,218,496\n",
      "             ReLU-16                 [-1, 4096]               0\n",
      "          Dropout-17                 [-1, 4096]               0\n",
      "           Linear-18                 [-1, 4096]      16,781,312\n",
      "             ReLU-19                 [-1, 4096]               0\n",
      "          Dropout-20                 [-1, 4096]               0\n",
      "           Linear-21                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 46,764,746\n",
      "Trainable params: 46,764,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 10.22\n",
      "Params size (MB): 178.39\n",
      "Estimated Total Size (MB): 188.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.to(device), input_size=(1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc745866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, time since epoch: 0.695. Train acc: 0.094. Train Loss: 2.303\n",
      "Step 10, time since epoch: 2.853. Train acc: 0.103. Train Loss: 2.365\n",
      "Step 20, time since epoch: 4.910. Train acc: 0.167. Train Loss: 2.250\n",
      "Step 30, time since epoch: 6.931. Train acc: 0.265. Train Loss: 2.027\n",
      "Step 40, time since epoch: 9.010. Train acc: 0.360. Train Loss: 1.784\n",
      "Step 50, time since epoch: 10.930. Train acc: 0.434. Train Loss: 1.589\n",
      "Step 60, time since epoch: 13.062. Train acc: 0.502. Train Loss: 1.409\n",
      "Step 70, time since epoch: 15.410. Train acc: 0.554. Train Loss: 1.268\n",
      "Step 80, time since epoch: 17.415. Train acc: 0.599. Train Loss: 1.142\n",
      "Step 90, time since epoch: 19.191. Train acc: 0.636. Train Loss: 1.041\n",
      "Step 100, time since epoch: 21.095. Train acc: 0.666. Train Loss: 0.957\n",
      "Step 110, time since epoch: 23.125. Train acc: 0.691. Train Loss: 0.887\n",
      "Step 120, time since epoch: 25.233. Train acc: 0.712. Train Loss: 0.828\n",
      "Step 130, time since epoch: 27.258. Train acc: 0.731. Train Loss: 0.775\n",
      "Step 140, time since epoch: 29.369. Train acc: 0.747. Train Loss: 0.729\n",
      "Step 150, time since epoch: 31.428. Train acc: 0.761. Train Loss: 0.688\n",
      "Step 160, time since epoch: 33.479. Train acc: 0.774. Train Loss: 0.653\n",
      "Step 170, time since epoch: 35.576. Train acc: 0.785. Train Loss: 0.622\n",
      "Step 180, time since epoch: 37.504. Train acc: 0.795. Train Loss: 0.594\n",
      "Step 190, time since epoch: 39.677. Train acc: 0.803. Train Loss: 0.570\n",
      "Step 200, time since epoch: 41.869. Train acc: 0.811. Train Loss: 0.548\n",
      "Step 210, time since epoch: 43.957. Train acc: 0.819. Train Loss: 0.526\n",
      "Step 220, time since epoch: 45.907. Train acc: 0.826. Train Loss: 0.506\n",
      "Step 230, time since epoch: 47.963. Train acc: 0.833. Train Loss: 0.487\n",
      "epoch 1, loss 0.4813, train acc 0.835, test acc 0.976, time 54.3 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 1\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train(net, train_iter, test_iter, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d368d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-kernel",
   "language": "python",
   "name": "new-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
